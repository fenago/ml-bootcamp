{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source https://github.com/fenago/ml-bootcamp/tree/master/lab-06-trees\n",
    "\n",
    "To download the dataset, run\n",
    "\n",
    "```\n",
    "wget https://github.com/fenago/ml-bootcamp/raw/master/lab-06-trees/CreditScoring.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head CreditScoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CreditScoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables are represented by numbers. For converting, we'll use the following map.\n",
    "\n",
    "```\n",
    "levels(dd$Status) = c(\"good\", \"bad\")\n",
    "levels(dd$Home) = c(\"rent\", \"owner\", \"priv\", \"ignore\", \"parents\", \"other\")\n",
    "levels(dd$Marital) = c(\"single\", \"married\", \"widow\", \"separated\", \"divorced\")\n",
    "levels(dd$Records) = c(\"no_rec\", \"yes_rec\")\n",
    "levels(dd$Job) = c(\"fixed\", \"partime\", \"freelance\", \"others\")\n",
    "```\n",
    "\n",
    "Let's convert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, all the categorical variables have strings, not numbers\n",
    "\n",
    "Let's look at numberical variables:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99999999 indicate missing values. Let's replace it by `NaN`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the stats are more meaninful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one record for which the status is unknown. Let's remove it - it's not useful for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.status != 'unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to prepare the data for training:\n",
    "\n",
    "* First, do train-validation-test split\n",
    "* Then, apply one-hot encoding to categorical features and get the feature matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (df_train.status == 'default').values\n",
    "y_val = (df_val.status == 'default').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['status']\n",
    "del df_val['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OHE, we'll use `DictVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we have some missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll replace them with \"0\" like in Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train = df_train.fillna(0).to_dict(orient='records')\n",
    "dict_val = df_val.fillna(0).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(dict_train)\n",
    "X_val = dv.transform(dict_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train a model. We'll start with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "\n",
    "We'll use `DecisionTreeClassifier` and for evaluating the quality of our models, we'll use AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the tree with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the predictions (probabilities), we use `predict_proba`. Let's check AUC on train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = dt.predict_proba(X_train)[:, 1]\n",
    "roc_auc_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And on validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a case of _overfitting_ - our model on the training data performs perfectly, but fails on validation\n",
    "\n",
    "Let's change the depth parameter: restring the size of the tree to 2 levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict_proba(X_train)[:, 1]\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('train auc: %.3f' % auc)\n",
    "\n",
    "y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print('val auc: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's even better than the previous tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=6)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in [1, 2, 3, 4, 5, 6, 10, 15, 20, None]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%4s -> %.3f' % (depth, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [1, 5, 10, 15, 20, 50, 100, 200]:\n",
    "    dt = DecisionTreeClassifier(max_depth=4, min_samples_leaf=m)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%s -> %.3f' % (m, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [4, 5, 6]:\n",
    "    print('depth: %s' % m)\n",
    "\n",
    "    for s in [1, 5, 10, 15, 20, 50, 100, 200]:\n",
    "        dt = DecisionTreeClassifier(max_depth=m, min_samples_leaf=s)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        print('%s -> %.3f' % (s, auc))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [1, 5, 10, 15, 20, 50, 100, 200]:\n",
    "    dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=m)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%s -> %.3f' % (m, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=15)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_val, y_pred_dt)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=0.7, linestyle='dashed', alpha=0.5)\n",
    "\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we repeat one more time - it changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how much it changes, we can repeat it 100 times and look at the mean and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(100):\n",
    "    rf = RandomForestClassifier(n_estimators=10)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    aucs.append(auc)\n",
    "\n",
    "auc_mean = np.mean(aucs)\n",
    "auc_std = np.std(aucs)\n",
    "\n",
    "print('%.3f +- %.3f' % (auc_mean, auc_std))\n",
    "print('%.3f -- %.3f' % (auc_mean -  auc_std, auc_mean + auc_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this issue, let's set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, random_state=3)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check how AUC depends on the number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10, 201, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=i, random_state=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%s -> %.3f' % (i, auc))\n",
    "    aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(range(10, 201, 10), aucs, color='black')\n",
    "plt.xticks(range(0, 201, 50))\n",
    "\n",
    "plt.title('Number of trees vs AUC')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_random_forest_n_estimators.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuninig the `max_depth` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_aucs = {}\n",
    "\n",
    "for depth in [5, 10, 20]:\n",
    "    print('depth: %s' % depth)\n",
    "    aucs = []\n",
    "\n",
    "    for i in range(10, 201, 10):\n",
    "        rf = RandomForestClassifier(n_estimators=i, max_depth=depth, random_state=1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        print('%s -> %.3f' % (i, auc))\n",
    "        aucs.append(auc)\n",
    "    \n",
    "    all_aucs[depth] = aucs\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "num_trees = list(range(10, 201, 10))\n",
    "\n",
    "plt.plot(num_trees, all_aucs[5], label='depth=5', color='black', linestyle='dotted')\n",
    "plt.plot(num_trees, all_aucs[10], label='depth=10', color='black', linestyle='dashed')\n",
    "plt.plot(num_trees, all_aucs[20], label='depth=20', color='black', linestyle='solid')\n",
    "    \n",
    "plt.xticks(range(0, 201, 50))\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Number of trees vs AUC')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_random_forest_n_estimators_depth.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the `min_samples_leaf` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_aucs = {}\n",
    "\n",
    "for m in [3, 5, 10]:\n",
    "    print('min_samples_leaf: %s' % m)\n",
    "    aucs = []\n",
    "\n",
    "    for i in range(10, 201, 20):\n",
    "        rf = RandomForestClassifier(n_estimators=i, max_depth=10, min_samples_leaf=m, random_state=1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        print('%s -> %.3f' % (i, auc))\n",
    "        aucs.append(auc)\n",
    "    \n",
    "    all_aucs[m] = aucs\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "num_trees = list(range(10, 201, 20))\n",
    "\n",
    "plt.plot(num_trees, all_aucs[3], label='min_samples_leaf=3', color='black', linestyle='dotted')\n",
    "plt.plot(num_trees, all_aucs[5], label='min_samples_leaf=5', color='black', linestyle='dashed')\n",
    "plt.plot(num_trees, all_aucs[10], label='min_samples_leaf=10', color='black', linestyle='solid')\n",
    "    \n",
    "plt.xticks(range(0, 201, 50))\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Number of trees vs AUC')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_random_forest_n_estimators_sample_leaf.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=5, random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_rf)\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_dt)\n",
    "plt.plot(fpr, tpr, color='black', linestyle='dashed')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=0.7, linestyle='dashed', alpha=0.5)\n",
    "\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=dv.feature_names_)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=dv.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'seed': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params, dtrain, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dval)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'), (dval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=100,\n",
    "                  evals=watchlist, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture this output, we can use \n",
    "\n",
    "- `%%capture` instruction that saves the result to `output`\n",
    "- `parse_xgb_output` function that parses it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=100,\n",
    "                  evals=watchlist, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xgb_output(output):\n",
    "    tree = []\n",
    "    aucs_train = []\n",
    "    aucs_val = []\n",
    "\n",
    "    for line in output.stdout.strip().split('\\n'):\n",
    "        it_line, train_line, val_line = line.split('\\t')\n",
    "\n",
    "        it = int(it_line.strip('[]'))\n",
    "        train = float(train_line.split(':')[1])\n",
    "        val = float(val_line.split(':')[1])\n",
    "\n",
    "        tree.append(it)\n",
    "        aucs_train.append(train)\n",
    "        aucs_val.append(val)\n",
    "\n",
    "    return tree, aucs_train, aucs_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use it for plotting the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, aucs_train, aucs_val = parse_xgb_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(tree, aucs_train, color='black', linestyle='dashed', label='Train AUC')\n",
    "plt.plot(tree, aucs_val, color='black', linestyle='solid', label='Validation AUC')\n",
    "plt.xticks(range(0, 101, 25))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('XGBoost: number of trees vs AUC')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_xgb_default.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning: eta\n",
    "\n",
    "First, we try to set eta to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_eta_03 = parse_xgb_output(output)\n",
    "print(max(aucs_val_eta_03))\n",
    "print(max(zip(aucs_val_eta_03, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_eta_01 = parse_xgb_output(output)\n",
    "print(max(aucs_val_eta_01))\n",
    "print(max(zip(aucs_val_eta_01, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_eta_005 = parse_xgb_output(output)\n",
    "print(max(aucs_val_eta_005))\n",
    "print(max(zip(aucs_val_eta_005, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_eta_001 = parse_xgb_output(output)\n",
    "print(max(aucs_val_eta_001))\n",
    "print(max(zip(aucs_val_eta_001, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(tree, aucs_val_eta_03, color='black', linestyle='solid', label='eta=0.3')\n",
    "plt.plot(tree, aucs_val_eta_01, color='black', linestyle='dashed', label='eta=0.1')\n",
    "# plt.plot(tree, aucs_val_eta_005, color='grey', linestyle='solid', label='eta=0.05')\n",
    "# plt.plot(tree, aucs_val_eta_001, color='grey', linestyle='dashed', label='eta=0.01')\n",
    "\n",
    "plt.xticks(range(0, 501, 100))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('The effect of eta on model performance')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC (validation)')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_xgb_eta.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(tree, aucs_val_eta_01, color='grey', linestyle='dashed', label='eta=0.1')\n",
    "plt.plot(tree, aucs_val_eta_005, color='black', linestyle='solid', label='eta=0.05')\n",
    "plt.plot(tree, aucs_val_eta_001, color='black', linestyle='dashed', label='eta=0.01')\n",
    "\n",
    "plt.xticks(range(0, 501, 100))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('The effect of eta on model performance')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC (validation)')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_xgb_eta_2.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning: max_depth\n",
    "\n",
    "First, try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_depth3 = parse_xgb_output(output)\n",
    "print(max(aucs_val_depth3))\n",
    "print(max(zip(aucs_val_depth3, tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_depth10 = parse_xgb_output(output)\n",
    "print(max(aucs_val))\n",
    "print(max(zip(aucs_val_depth10, tree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With depth=3 it's better than depth=6 and depth=10. So let's try 4 to see if it's better than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, _, aucs_val_depth4 = parse_xgb_output(output)\n",
    "print(max(aucs_val_depth4))\n",
    "print(max(zip(aucs_val_depth4, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(tree, aucs_val_depth3, color='black', linestyle='dashed', label='max_depth=3')\n",
    "plt.plot(tree, aucs_val_depth4, color='grey', linestyle='dashed', label='max_depth=4')\n",
    "plt.plot(tree, aucs_val_eta_01, color='black', linestyle='solid', label='max_depth=6')\n",
    "plt.plot(tree, aucs_val_depth10, color='grey', linestyle='solid', label='max_depth=10')\n",
    "\n",
    "plt.ylim(0.75, 0.845)\n",
    "plt.xlim(-10, 510)\n",
    "plt.xticks(range(0, 501, 100))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('The effect of max_depth on model performance')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC (validation)')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_xgb_depth.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not better, so we'll leave it at 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune \"min_child_weight\"\n",
    "\n",
    "First, the default value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree, _, aucs_val_mcw1 = parse_xgb_output(output)\n",
    "print(max(aucs_val_mcw1))\n",
    "print(max(zip(aucs_val_mcw1, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 10,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree, _, aucs_val_mcw10 = parse_xgb_output(output)\n",
    "print(max(aucs_val_mcw10))\n",
    "print(max(zip(aucs_val_mcw10, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 30,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree, _, aucs_val_mcw30 = parse_xgb_output(output)\n",
    "print(max(aucs_val_mcw30))\n",
    "print(max(zip(aucs_val_mcw30, tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(tree, aucs_val_mcw1, color='black', linestyle='solid', label='min_child_weight=1')\n",
    "plt.plot(tree, aucs_val_mcw10, color='grey', linestyle='solid', label='min_child_weight=10')\n",
    "plt.plot(tree, aucs_val_mcw30, color='black', linestyle='dashed', label='min_child_weight=30')\n",
    "\n",
    "plt.ylim(0.82, 0.84)\n",
    "plt.xlim(0, 510)\n",
    "plt.xticks(range(0, 501, 100))\n",
    "plt.yticks(np.linspace(0.82, 0.84, 5))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('The effect of min_child_weight on model performance')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC (validation)')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_xgb_mcw.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the best number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=500, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree, _, aucs_val = parse_xgb_output(output)\n",
    "print(max(aucs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max(zip(aucs_val, tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(tree, aucs_val, color='black', linestyle='solid')\n",
    "\n",
    "\n",
    "plt.ylim(0.80, 0.84)\n",
    "plt.xlim(0, 510)\n",
    "plt.xticks(range(0, 501, 100))\n",
    "plt.yticks(np.linspace(0.80, 0.84, 9))\n",
    "\n",
    "\n",
    "plt.vlines(180, 0, 1, color='grey', linestyle='dashed', linewidth=0.9)\n",
    "\n",
    "plt.title('Selecting the number of trees')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC (validation)')\n",
    "\n",
    "# plt.savefig('ch06-figures/06_xgb_number_trees.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain,\n",
    "                  num_boost_round=180, verbose_eval=10,\n",
    "                  evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_val, y_pred_dt))\n",
    "print(roc_auc_score(y_val, y_pred_rf))\n",
    "print(roc_auc_score(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_xgb)\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_rf)\n",
    "plt.plot(fpr, tpr, color='grey', linestyle='dashed', alpha=0.9)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_dt)\n",
    "plt.plot(fpr, tpr, color='grey', linestyle='dashed', alpha=0.9)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=0.7, linestyle='dashed', alpha=0.5)\n",
    "\n",
    "plt.xlim([-0.02, 1.02])\n",
    "plt.ylim([-0.02, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = (df_train_full.status == 'default').values\n",
    "y_test = (df_test.status == 'default').values\n",
    "\n",
    "del df_train_full['status']\n",
    "del df_test['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train_full = df_train_full.fillna(0).to_dict(orient='records')\n",
    "dict_test = df_test.fillna(0).to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_full = dv.fit_transform(dict_train_full)\n",
    "X_test = dv.transform(dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_leaf=5, random_state=1)\n",
    "rf_final.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_full = xgb.DMatrix(X_train_full, label=y_train_full, feature_names=dv.feature_names_)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=dv.feature_names_)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "}\n",
    "\n",
    "num_trees = 160\n",
    "\n",
    "xgb_final = xgb.train(xgb_params, dtrain_full, num_boost_round=num_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_final.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_test, y_pred_rf))\n",
    "print(roc_auc_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(dv.feature_names_, dt.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(zip(dv.feature_names_, dt.feature_importances_))\n",
    "\n",
    "df_importance = pd.DataFrame(importances, columns=['feature', 'gain'])\n",
    "df_importance = df_importance.sort_values(by='gain', ascending=False)\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = df_importance[df_importance.gain > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(df_importance)\n",
    "plt.barh(range(num), df_importance.gain[::-1])\n",
    "plt.yticks(range(num), df_importance.feature[::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importances = list(zip(dv.feature_names_, rf.feature_importances_))\n",
    "\n",
    "df_importance = pd.DataFrame(importances, columns=['feature', 'gain'])\n",
    "df_importance = df_importance.sort_values(by='gain', ascending=False)\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = df_importance[df_importance.gain > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(df_importance)\n",
    "plt.barh(range(num), df_importance.gain[::-1])\n",
    "plt.yticks(range(num), df_importance.feature[::-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.get_score(importance_type='gain')\n",
    "scores = sorted(scores.items(), key=lambda x: x[1])\n",
    "list(reversed(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.get_score(importance_type='weight')\n",
    "scores = sorted(scores.items(), key=lambda x: x[1])\n",
    "list(reversed(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [n for (n, s) in scores]\n",
    "scores = [s for (n, s) in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "\n",
    "plt.barh(np.arange(len(scores)), scores)\n",
    "plt.yticks(np.arange(len(names)), names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Extremely randomized trees\n",
    "\n",
    "Similar to random forest, but more random. Instead of selecting the best split among all posible splits, ET picks a few candidate splits at random and then select the best one among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aucs = []\n",
    "\n",
    "for i in range(10, 201, 10):\n",
    "    rf = ExtraTreesClassifier(n_estimators=i, max_depth=30)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print('%s -> %.3f' % (i, auc))\n",
    "    aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
